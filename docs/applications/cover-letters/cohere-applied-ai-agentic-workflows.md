# Cover Letter: Cohere — Applied AI Engineer, Agentic Workflows

**Role:** Applied AI Engineer — Agentic Workflows
**Apply:** https://jobs.ashbyhq.com/cohere/1fa01a03-9253-4f62-8f10-0fe368b38cb9
**Salary:** Not disclosed

---

agentic-titan coordinates multiple AI agents through 18 development phases with 1,095 tests covering coordination, message passing, and fault tolerance. a-i-council--coliseum implements multi-agent deliberation — agents debating positions and synthesizing conclusions. Both systems enforce the same governance model: constitutional constraints, automated validation, and evaluation frameworks that assess output quality. That infrastructure maps directly to the Applied AI Engineer, Agentic Workflows role at Cohere.

## Why Agentic Workflows at Cohere

Cohere is building the enterprise layer for agentic AI. Enterprise means governance: who can an agent call, what can it access, when should it stop? I've answered these questions for a real system. The eight-organ architecture enforces constitutional constraints — no circular dependencies, no back-edges, promotion through a formal state machine — and these rules aren't suggestions. They're automated. They block merges. They run monthly audits. That's the kind of orchestration design that makes agentic workflows safe enough for enterprise customers to deploy.

## What I'd Bring

**Multi-agent orchestration, tested at scale.** agentic-titan is a multi-agent orchestration framework I built through 18 development phases with 1,095 tests covering agent coordination, message passing, fault tolerance, and graceful degradation. This isn't a prototype — it's a system designed to evaluate how agents behave when things go wrong, not just when things go right.

**Agent deliberation systems.** a-i-council--coliseum implements multi-agent deliberation: AI agents with distinct perspectives debating positions and synthesizing conclusions. This is the kind of multi-step reasoning workflow — plan, execute, evaluate, refine — that your role designs for enterprise customers. I've built the architecture and the evaluation framework to assess whether the synthesis is actually good.

**Symbolic systems with real depth.** recursive-engine--generative-entity implements a symbolic operating system with a custom DSL, 21 organ handlers, and 1,254 tests at 85% coverage. I understand the internals of how agent systems maintain state, route messages, and handle complex multi-step reasoning — not just how to prompt them.

**Evaluation infrastructure as a first-class concern.** I built organ-audit.py (monthly health monitoring across 103 repos), platinum-validation.py (full system sweep against 1,267 audited links and 43 dependency edges), and 5 GitHub Actions workflows that enforce governance continuously. Evaluation framework building isn't a secondary skill — it's central to how I design systems.

**Documentation that scales enterprise adoption.** 809,812+ words of portfolio-quality documentation. When enterprise customers need to understand what an agentic system does and why they should trust it, clear technical communication is the difference between a proof-of-concept and a deployment.

## Evidence

- **agentic-titan:** 1,095 tests, 18 phases, multi-agent orchestration (organvm-iv-taxis/agentic-titan)
- **a-i-council--coliseum:** Multi-agent deliberation and synthesis (organvm-ii-poiesis/a-i-council--coliseum)
- **recursive-engine:** 1,254 tests, 85% coverage, symbolic OS with custom DSL (organvm-i-theoria/recursive-engine--generative-entity)
- **organvm-corpvs-testamentvm:** Governance infrastructure for 103-repo system (meta-organvm/organvm-corpvs-testamentvm)
- **Portfolio:** https://4444j99.github.io/portfolio/

I build agentic systems that are governed, tested, and documented — because that's what enterprise deployment requires.
