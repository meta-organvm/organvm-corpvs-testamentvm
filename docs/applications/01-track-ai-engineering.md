# Track: AI Engineering Roles

**Targets:** Anthropic, OpenAI, Runway, Together AI, Hugging Face, + 2 TBD
**Evidence:** 103-repo system with automated governance, 2,349 tests across flagship projects, 5 CI/CD governance workflows, ~404K+ words of documentation
**Core evidence:** ORGAN-IV orchestration + agentic-titan + recursive-engine

---

## Framing

"I designed and implemented an eight-organ orchestration system coordinating 103 repos across 8 orgs with automated governance, dependency validation, and health checks."

This positions you as someone who:
1. **Thinks in systems**, not fragments — orchestrating 100 repos is an architectural challenge
2. **Ships production-quality infrastructure** — 82+ CI/CD workflows, 5 governance automations, automated health checks
3. **Designs governance from first principles** — promotion state machine, dependency rules, constitutional constraints
4. **Tests rigorously** — agentic-titan: 1,095 tests; recursive-engine: 1,254 tests
5. **Documents thoroughly** — ~404K+ words of documentation is evidence of communication capacity

---

## Target-Specific Angles

### Anthropic — AI Systems Engineer
**Why you fit:** Anthropic builds AI systems that require governance, safety constraints, and orchestration. Your eight-organ system *is* a governance system.

**Lead with:**
- ORGAN-IV orchestration: registry-as-truth, dependency validation, constitutional constraints
- Governance-rules.json: encoding rules that the system enforces automatically
- Trade-off analysis: Why a promotion state machine? Why no back-edges? Why transitive depth <= 4?
- organ-audit.py: Automated health monitoring across a complex system

**Talking points:**
- "I built a system where governance rules are data, not code — the system reads governance-rules.json and enforces constraints automatically"
- "The dependency validation ensures no circular dependencies across 103 repos — the same kind of constraint enforcement that matters in AI safety"
- "Monthly automated audits with 0 critical alerts demonstrate that governance-first design works at scale"

### OpenAI — Applied AI Engineer
**Why you fit:** OpenAI values builders who ship complex systems. agentic-titan is evidence of multi-agent system design.

**Lead with:**
- agentic-titan: 1,095 tests, 18 development phases, multi-agent orchestration
- The eight-organ system as meta-evidence: you orchestrate agents *and* the infrastructure they run on
- Production deployment patterns: CI/CD across 70+ repos, automated validation

**Talking points:**
- "agentic-titan went through 18 development phases with 1,095 tests — that's the kind of rigor I bring to production AI systems"
- "I don't just build AI agents; I build the governance and infrastructure that makes them reliable"

### Runway / Together AI / Hugging Face — ML Infra or Developer Advocate
**Why you fit:** These companies need people who can bridge technical depth with clear communication. Your ~404K+ words of documentation + working systems = evidence of both.

**Lead with:**
- The meta-system itself: 100 repos documented, organized, and automated
- Public-process essays as evidence of developer advocacy capacity
- recursive-engine as evidence of ML/AI depth (symbolic systems, ontological processing)

**Talking points:**
- "I've documented 100 repositories at portfolio quality — every README is written for grant reviewers and hiring managers, not just developers"
- "My ORGAN-V public process essays explain complex systems to non-technical audiences"

---

## Cover Letter Template

> [One sentence: what the system does that's relevant to THIS role]
> [One sentence: a specific metric or mechanism]
> [Then: how this connects to the role]
>
> The eight-organ system I designed coordinates 103 repositories across 8 GitHub organizations. The system includes:
>
> - A machine-readable registry serving as single source of truth for all repos
> - Automated dependency validation enforcing no circular dependencies and no back-edges
> - A formal promotion state machine with 5 GitHub Actions workflows for autonomous governance
> - 94+ CI/CD pipelines and automated monthly health audits
> - ~404K+ words of documentation across the entire system
>
> Two projects demonstrate particular depth:
>
> - **agentic-titan** — A multi-agent orchestration framework with 1,095 tests across 18 development phases. This represents my approach to building reliable AI systems: phased development, comprehensive testing, clear architectural boundaries.
>
> - **recursive-engine** — A symbolic operating system with 1,254 tests and 85% coverage, implementing 21 organ handlers for myth, identity, ritual, and recursive systems. This shows my comfort with abstract formal systems translated into production code.
>
> [COMPANY-SPECIFIC CONNECTION: how a specific aspect of the system maps to what the company builds]
>
> The eight-organ system applies production governance rigor to creative infrastructure — and the transparency of building it in public made it better.
>
> Portfolio: github.com/meta-organvm
> Public process: github.com/organvm-v-logos/public-process

---

## Project Highlight: agentic-titan

**What:** Multi-agent orchestration framework
**Where:** organvm-iv-taxis/agentic-titan
**Evidence:** 1,095 tests, 18 development phases
**Relevance:** Directly demonstrates AI systems engineering

Key points:
- Multi-phase development with clear architectural milestones
- Comprehensive test coverage across agent coordination, message passing, fault tolerance
- Production-oriented design: monitoring, logging, graceful degradation
- Integration with the broader eight-organ governance model

## Project Highlight: recursive-engine

**What:** Symbolic operating system for myth, identity, ritual, and recursive systems
**Where:** organvm-i-theoria/recursive-engine--generative-entity
**Evidence:** 1,254 tests, 85% coverage, 21 organ handlers, ritual syntax DSL
**Relevance:** Demonstrates comfort with abstract formal systems + production implementation

Key points:
- Pure Python, well-tested, clearly documented
- DSL design (ritual syntax) shows language design capacity
- Integration with external systems (Obsidian, Git, Max/MSP)
- Bridges theory and implementation — exactly what AI research labs need

---

## Interview Preparation Notes

**Expected questions and how to answer using the system:**

Q: "Tell me about a complex system you've built."
A: 103 repositories across 8 GitHub organizations, coordinated by a machine-readable registry, automated dependency validation, and a promotion state machine. Walk through the architectural decisions: why 8 organs (domain separation), why a state machine (governance without human bottlenecks), why dependency validation (structural integrity at scale).

Q: "How do you handle system failures?"
A: organ-audit.py runs monthly health checks across all 103 repos. governance-rules.json defines critical vs. warning thresholds. The validate-dependencies workflow blocks merges that would violate constraints. 0 critical alerts since launch.

Q: "How do you test at scale?"
A: 94+ CI/CD workflows across all code repos. agentic-titan: 1,095 tests across 18 development phases. recursive-engine: 1,254 tests, 85% coverage. platinum-validation.py sweeps the full system against 1,267 audited links and 43 dependency edges.

Q: "How do you communicate technical decisions?"
A: ~404K+ words of documentation across 100 repos. 42 published essays. orchestration-system-v2.md documents governance rationale. Every README is written for external evaluators, not internal notes.
